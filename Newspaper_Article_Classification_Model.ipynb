{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IpkIt7N8Ti9XU0ofIOcDk6lBj1cpasg2",
      "authorship_tag": "ABX9TyMPWkEdMZMvHPzb8o1cWnTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noahlie07/Newspaper-Article-Classification-Model/blob/main/Newspaper_Article_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Newspaper Article Classification Model"
      ],
      "metadata": {
        "id": "OeMSEktc1EM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part I: Text Preprocessing"
      ],
      "metadata": {
        "id": "q_NIm99t1MXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "wb6J_Hdh1SyM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the dataset\n",
        "df = pd.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
        "\n",
        "# Dropping irrelevant columns\n",
        "df = df.drop(columns=[\"link\", \"authors\", \"date\"])\n",
        "\n",
        "# Dropping duplicate rows and rows containing missing values\n",
        "df = df.drop_duplicates()\n",
        "df = df.dropna()\n",
        "\n",
        "# Load in the necessary NLTK tools\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the stop words and Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Text Preprocessing\n",
        "def text_preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "df[\"short_description\"] = df[\"short_description\"].apply(text_preprocessing)\n",
        "df[\"headline\"] = df[\"headline\"].apply(text_preprocessing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S01A2hCr1V5f",
        "outputId": "acbbe323-16a4-4631-ff4b-90c545a7e70c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Feature Engineering"
      ],
      "metadata": {
        "id": "rq8UQ80o1aTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding for target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
        "\n",
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['short_description', 'headline']], df['category_encoded'], test_size=0.2, random_state=7)\n",
        "\n",
        "# Converting Description and Headlines into numerical representations\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_short_desc = vectorizer.fit_transform(X_train['short_description'])\n",
        "X_test_short_desc = vectorizer.transform(X_test['short_description'])\n",
        "X_train_headline = vectorizer.fit_transform(X_train['headline'])\n",
        "X_test_headline = vectorizer.transform(X_test['headline'])"
      ],
      "metadata": {
        "id": "7YKP1xVz1kwT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part III: Machine Learning"
      ],
      "metadata": {
        "id": "NPBibvtk1lix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the feature matrices\n",
        "X_train_combined = hstack([X_train_short_desc, X_train_headline])\n",
        "X_test_combined = hstack([X_test_short_desc, X_test_headline])\n",
        "\n",
        "# Logistic Regression model training\n",
        "model = LogisticRegression(max_iter=1000, random_state=7)\n",
        "model.fit(X_train_combined, y_train)\n",
        "\n",
        "# Generating predictions\n",
        "y_pred = model.predict(X_test_combined)\n",
        "\n",
        "# Calculating Accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generating classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CULHTzx41nlC",
        "outputId": "a6730c3c-07ea-4802-9165-655f9075b97c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.6039\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.34      0.24      0.28       290\n",
            "ARTS & CULTURE       0.39      0.24      0.30       254\n",
            "  BLACK VOICES       0.49      0.40      0.44       909\n",
            "      BUSINESS       0.48      0.46      0.47      1237\n",
            "       COLLEGE       0.52      0.34      0.41       234\n",
            "        COMEDY       0.50      0.46      0.48      1087\n",
            "         CRIME       0.54      0.55      0.54       729\n",
            "CULTURE & ARTS       0.60      0.25      0.36       232\n",
            "       DIVORCE       0.82      0.69      0.75       695\n",
            "     EDUCATION       0.41      0.29      0.34       199\n",
            " ENTERTAINMENT       0.62      0.74      0.67      3508\n",
            "   ENVIRONMENT       0.43      0.26      0.32       289\n",
            "         FIFTY       0.34      0.16      0.22       280\n",
            "  FOOD & DRINK       0.65      0.72      0.68      1275\n",
            "     GOOD NEWS       0.42      0.27      0.33       270\n",
            "         GREEN       0.39      0.34      0.36       539\n",
            "HEALTHY LIVING       0.34      0.38      0.36      1300\n",
            " HOME & LIVING       0.75      0.72      0.73       868\n",
            "        IMPACT       0.36      0.28      0.32       720\n",
            " LATINO VOICES       0.65      0.28      0.39       219\n",
            "         MEDIA       0.55      0.44      0.48       572\n",
            "         MONEY       0.54      0.40      0.46       361\n",
            "     PARENTING       0.54      0.57      0.55      1737\n",
            "       PARENTS       0.36      0.37      0.37       745\n",
            "      POLITICS       0.69      0.83      0.76      7095\n",
            "  QUEER VOICES       0.76      0.64      0.69      1265\n",
            "      RELIGION       0.60      0.47      0.52       485\n",
            "       SCIENCE       0.61      0.44      0.51       428\n",
            "        SPORTS       0.68      0.67      0.68      1014\n",
            "         STYLE       0.46      0.39      0.42       424\n",
            "STYLE & BEAUTY       0.80      0.78      0.79      1973\n",
            "         TASTE       0.42      0.30      0.35       410\n",
            "          TECH       0.52      0.47      0.49       412\n",
            " THE WORLDPOST       0.50      0.43      0.46       765\n",
            "        TRAVEL       0.70      0.77      0.74      1981\n",
            "     U.S. NEWS       0.38      0.13      0.19       292\n",
            "      WEDDINGS       0.79      0.77      0.78       713\n",
            "    WEIRD NEWS       0.40      0.32      0.36       553\n",
            "      WELLNESS       0.61      0.73      0.67      3549\n",
            "         WOMEN       0.37      0.32      0.34       707\n",
            "    WORLD NEWS       0.47      0.38      0.42       646\n",
            "     WORLDPOST       0.50      0.38      0.44       551\n",
            "\n",
            "      accuracy                           0.60     41812\n",
            "     macro avg       0.53      0.45      0.48     41812\n",
            "  weighted avg       0.59      0.60      0.59     41812\n",
            "\n"
          ]
        }
      ]
    }
  ]
}